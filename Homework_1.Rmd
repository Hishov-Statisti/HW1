---
title: "Exercies 1 - Alon Goodman & Ran Hassid"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r message=FALSE, warning=FALSE}
#install.packages("stringi")
#install.packages("LearnGeom")
#install.packages("kntir")
library(knitr)
library(stringi)
library(LearnGeom)
```

# Question 1 #

## a ##

We chose 'dog' to be our 'word'.

We assume only lowercase letters are available in the keyboard (= 26 options)

Therefore, the expected value is E(2+G(1/26^3)) = 2 + 26^3 = 17578

## b ##

```{r}
result_vec_Q1 <- numeric(10000)
for (i in 1:10000) {
  counter <- 3
  monkey_word <- stri_rand_strings(n = 1, length = 3, pattern = "[a-z]")
  while (monkey_word != 'dog')
  {
    counter <- counter + 1
    stri_sub(monkey_word, from=4L, to=-1L) <- stri_rand_strings(n = 1, length = 1, pattern = "[a-z]")
    monkey_word <- stri_sub(monkey_word, from=2L, to=4L)
    
  }
  
  result_vec_Q1[i] <- counter
}
```

```{r}
mean(result_vec_Q1)
```

The result of the simulation seems to be consistent with the theoretical result.
We wanted to check if the result is close enough. On the one hand the theoretical result is within the confidence interval, but the confidence interval is very wide.

```{r}
quantile(x = result_vec_Q1,probs = c(.025,.975))
```

## c ##

The number of keystrokes is blocked from below by 3 but not blocked from above.
We can get a high number of keystrokes with a low probability (larger than the expected value and also twice the expected value). Therefore, it is observed that the number of keystrokes will come from an asymmetrical distribution with a right tail (as mentioned, the number of keystrokes is geometrically distributed and this distribution is asymmetrical). Therefore, we assume that the median will be lower than expected.


```{r}
plot(density(result_vec_Q1), xlab = "Number of Keystrokes",main = "Emprical density of Keystrokes")
```

# Question 2 #

```{r}
result_vec_Q2 <- numeric(10000)
for (i in 1:10000) {
  p.1 <- runif(2)
  p.2 <- runif(2)
  p.3 <- runif(2)
  
  result_vec_Q2[i] <- max(Angle(p.1,p.2,p.3),Angle(p.2,p.1,p.3),Angle(p.1,p.3,p.2))
}
```

The estimate value for obtuse angle:
```{r}
p_Q2 <- mean(result_vec_Q2>90)
p_Q2
```
C.I of the probability to get obtuse angle (C.I for proportion):

```{r}
p_Q2 + (pnorm(.025)*sqrt(p_Q2*(1-p_Q2)/10000))*c(-1,1)
```

The probability to get a right-angled triangle is zero:
```{r}
mean(result_vec_Q2==90)
```

# Question 3 #

## a ##

```{r}
res_vec_Q3 <- numeric(10000)
for (i in 1:10000) {
  res_vec_Q3[i] <- abs(median(rnorm(500)))
}
```

pr(|Mu_statisti| >= Mu) 
```{r}
p_Q3 <- quantile(x = res_vec_Q3, probs = .95)
p_Q3
```

## b ##

```{r}
res_vec_Q3B <- numeric(10000)
for (i in 1:10000) {
  res_vec_Q3B[i] <- abs(median(rnorm(n = 500,mean = 0.1,sd = 1)))
}
```

The estimate of the Power (the proportion of rejects):
```{r}
mean(res_vec_Q3B>p_Q3)
```

The part of the analytical calculation of the power for a test based on the mean is in the attached pdf file.

It can be seen that its power is higher than that of the median-based test so we will prefer it.


# Question 4 #

## a ##

Board Game:

1 2 3

4 5 6

7 8 9

Auxiliary function - simulate the option of a cat to move in the next step on the board game.

```{r}
cat_move <- function(num_1)
{
  if(num_1 == 1){
    num_1 <- sample(x = c(2,4,5),size = 1)
    return(num_1)}
  if(num_1 == 2){
    num_1 <- sample(x = c(1,3,4,5,6),size = 1)
    return(num_1)}
  if(num_1 == 3){
    num_1 <- sample(x = c(2,5,6),size = 1)
    return(num_1)}
  if(num_1 == 4){
    num_1 <- sample(x = c(1,2,5,7,8),size = 1)
    return(num_1)}
  if(num_1 == 5){
    num_1 <- sample(x = c(1,2,3,4,6,7,8,9),size = 1)
    return(num_1)}
  if(num_1 == 6){
    num_1 <- sample(x = c(2,3,5,8,9),size = 1)
    return(num_1)}
  if(num_1 == 7){
    num_1 <- sample(x = c(4,5,8),size = 1)
    return(num_1)}
  if(num_1 == 8){
    num_1 <- sample(x = c(4,5,6,7,9),size = 1)
    return(num_1)}
  if(num_1 == 9){
    num_1 <- sample(x = c(5,6,8),size = 1)
    return(num_1)}
}
```

Initialization:

```{r}
cat_1 <- 1
cat_2 <- 9
```

Lets the Game Begin!

```{r}
round_number <- vector(length = 1050)

for (i in 1:1050) {
  cat_1 <- cat_move(cat_1)
  cat_2 <- cat_move(cat_2)
  ifelse(cat_1==cat_2,yes = round_number[i] <- TRUE,no = round_number[i] <- FALSE)
}
```

The probability that both cats are in the same cell: 

```{r}
mean(round_number[51:1050])
```

# Question 5 #

## a1 ##
```{r}
gamble <- function(target_value,start_value,win_prob,gamble_value){
  while((start_value > 0) && (start_value<target_value)){
    himur <- min(target_value-start_value,start_value,gamble_value)
    x <- rbinom(n=1,size = 1,prob = win_prob)
    ifelse(x==1,start_value <- start_value+himur,start_value <- start_value-himur)
  }
  start_value==target_value
}

gamble_value <- c(.1,.5,1,2)
win_win_0.6 <- numeric(4)
for(i in 1:4){
  win_win_0.6[i] <- mean(replicate(10000,gamble(5,2,0.6,gamble_value[i])))
}
win_win_0.6
data.frame(gamble_value,win_win_0.6)

```
The optimal strategy is to start with the fixed bet amount 0.1.

## a2 ##

```{r}
gamble_value <- c(.1,.5,1,2)
win_win_0.4 <- numeric(4)
for(i in 1:4){
  win_win_0.4[i] <- mean(replicate(10000,gamble(10,4,0.4,gamble_value[i])))
}
win_win_0.4
data.frame(gamble_value,win_win_0.4)
```
The optimal strategy is to start with the fixed bet amount 2

## b ##

The new strategy is if we lose then we double the bet
```{r}
new_gamble <- function(target_value,start_value,win_prob,gamble_value){
  himur <- min(target_value-start_value,start_value,gamble_value)
  while((start_value > 0) && (start_value<target_value))
    {
      x <- rbinom(n=1,size = 1,prob = win_prob)
      if(x==1){
        start_value <- start_value+himur
        himur <- min(target_value-start_value,start_value,gamble_value)
      }
      if(x==0){
          start_value <- start_value-himur
          himur <-min(target_value-start_value,start_value,gamble_value*2)
      }
    }
  start_value==target_value
}

```

```{r}
gamble_value <- c(.1,.5,1,2)
win_win_0.6_new <- numeric(4)
for(i in 1:4){
  win_win_0.6_new[i] <- mean(replicate(10000,new_gamble(5,2,0.6,gamble_value[i])))
}
win_win_0.6_new
data.frame(gamble_value,win_win_0.6,win_win_0.6_new)

```

```{r}
gamble_value <- c(.1,.5,1,2)
win_win_0.4_new <- numeric(4)
for(i in 1:4){
  win_win_0.4_new[i] <- mean(replicate(10000,new_gamble(10,4,0.4,gamble_value[i])))
}
win_win_0.4_new
data.frame(gamble_value,win_win_0.4,win_win_0.4_new)
```

## c ##


```{r}
gamble_val <- c(.1,.5,1,2)
p <- c(.1,.25,.5,.75,.9)

mat_a5_sv1 <- matrix(1:20, nrow = 4, ncol = 5,dimnames = list(gamble_val,p))
for(i in 1:4){
  for(j in 1:5){
    mat_a5_sv1[i,j] <- mean(replicate(10000,gamble(5,1,p[j],gamble_val[i])))
  }}
mat_a5_sv1
```


```{r}
mat_a6_sv2 <- matrix(1:20, nrow = 4, ncol = 5,dimnames = list(gamble_val,p))
for(i in 1:4){
  for(j in 1:5){
    mat_a6_sv2[i,j] <- mean(replicate(10000,gamble(6,2,p[j],gamble_val[i])))
  }}
mat_a6_sv2
```


```{r}
mat_a8_sv3 <- matrix(1:20, nrow = 4, ncol = 5,dimnames = list(gamble_val,p))
for(i in 1:4){
  for(j in 1:5){
    mat_a8_sv3[i,j] <- mean(replicate(10000,gamble(8,3,p[j],gamble_val[i])))
  }}
mat_a8_sv3
```


```{r}
mat_a10_sv4 <- matrix(1:20, nrow = 4, ncol = 5,dimnames = list(gamble_val,p))
for(i in 1:4){
  for(j in 1:5){
    mat_a10_sv4[i,j] <- mean(replicate(10000,gamble(10,4,p[j],gamble_val[i])))
  }}
mat_a10_sv4
```

The optimal strategy for p<0.5 is to start with the biggest bet amount.
The optimal strategy for p>0.5 is to start with the lowest bet amount.
For p=0.5 there is no clear strategy.
An intuitive explanation for this is that when the probability of winning increases there is no reason to invest a large amount in a bet to reach the final goal. 
But if the probability of winning are low you should invest a large bet amount to try and reach the final goal.



